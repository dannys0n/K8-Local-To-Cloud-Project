⚠️ This README was automatically generated by AI (keyword-retrieval RAG → OpenRouter → LLM) every push to main via Actions and may be inaccurate.
Model: stepfun/step-3.5-flash:free
Generated: 2026-02-17 08:06 UTC

---
# Kubernetes Game Server System

A scalable game server architecture using Kubernetes for matchmaking and session management, with a load testing tool for simulation.

## Overview

This system implements a game backend that:
- Manages player matchmaking via a Redis-backed queue
- Creates dedicated game server pods (as Kubernetes Deployments) for each match
- Provides a TCP-based authoritative game server per match
- Includes a load testing client simulator

Components:
- **Backend** (FastAPI): Handles matchmaking requests, persists match data to PostgreSQL, and orchestrates game server pod creation.
- **Game Server** (TCP): Authoritative server running per match in its own Kubernetes pod, managing state transitions (open → running → stop).
- **Load Tester**: Simulates multiple client lifecycles (join, play, end) to test scalability.

## Architecture

```
┌─────────┐     ┌────────────┐     ┌─────────────┐     ┌─────────────┐
│ Client  │────▶│   Proxy    │────▶│   Backend   │────▶│ K8s Cluster │
│ (Load)  │     │ (Port 8080)│     │ (FastAPI)   │     │             │
└─────────┘     └────────────┘     └─────────────┘     │   ├─ Redis   │
                                                        │   ├─ Postgres│
                                                        │   └─ Game    │
                                                        │      Servers │
                                                        └─────────────┘
```

1. **Matchmaking Flow**:
   - Clients POST to `/api/match/join` (via proxy) with `player_id`.
   - Backend enqueues player in Redis and monitors queue size.
   - When enough players are queued (or partial session criteria met), backend:
     - Creates a unique session ID.
     - Spawns a game server pod via Kubernetes API.
     - Records session metadata in PostgreSQL.
     - Returns connection details (`connect_host`, `connect_port`) to client.
   - Clients connect directly to the game server via TCP.

2. **Game Server Session**:
   - Each match runs in an isolated pod (`game-server-<session_id[:8]>`).
   - TCP protocol:
     - `GET_STATE`: Returns current state (`open`, `running`, `stop`).
     - `REQUEST_MATCH <seconds>`: First client sets match duration; transitions to `running`.
     - Automatically stops after duration or if all clients disconnect.
   - Backend tracks active sessions in Redis for quick lookup.

3. **Data Storage**:
   - **PostgreSQL**: Persistent match records (`session_id`, `players_json`, `backend_pod`, `game_server_pod`, timestamps). Schema auto-migrated.
   - **Redis**: In-memory queue (`matchmaking_queue`), active session registry (`active_sessions`), and per-session connection data with TTL.

## Prerequisites

- Docker
- [kind](https://kind.sigs.k8s.io/) (Kubernetes in Docker)
- kubectl
- Python 3.10+ (for load tester)
- Internet access (to pull base images if needed)

Local setup uses `kind` cluster named `dev` (configurable via `KIND_CLUSTER` in Makefile).

## Setup & Deployment

### 1. Start Local Cluster & Infrastructure

```bash
# Creates kind cluster, monitoring, databases (Redis & Postgres), and sets up port-forwards
make up
```

This runs scripts in `src/scripts/` to:
- Create cluster (`cluster.sh`)
- Deploy monitoring (`monitors.sh`)
- Deploy managers (`managers.sh`)
- Deploy databases (`databases` target) in `databases` namespace with port-forwards.

### 2. Deploy Game Services

```bash
# Builds Docker images, loads them into kind, and deploys backend, proxy, and game server
make game-testbed
```

This performs:
- Builds `game-backend:local`, `game-proxy:local`, `game-server:local`
- Loads images into kind cluster
- Applies Kubernetes manifests in `src/k8s/base/`:
  - `backend.yaml` (with RBAC and HPA)
  - `proxy.yaml` (with HPA)
- Note: Game server pods are created dynamically by the backend (not via static manifest).

### 3. Verify Deployment

```bash
# Check pods (backend, proxy, databases)
kubectl get pods -n default
kubectl get pods -n databases
```

Backend and proxy should be running. The proxy (`game-proxy` service) is exposed via port-forward on `localhost:8080`.

## Running the Load Test

The load tester (`src/app/load/`) simulates realistic client behavior:

```bash
# Run with default 50 clients, 30s match duration
make game-load-local

# Customize via environment variables or Makefile CLIENTS var
CLIENTS=100 make game-load-local

# With spawn rate (clients/sec) and custom target URL
SPAWN_RATE=10 MATCH_DURATION=60 TARGET_URL=http://localhost:8080 CLIENTS=200 make game-load-local
```

**Environment Variables** (for load tester):
- `CLIENTS`: Number of concurrent clients (default 50)
- `TARGET_URL`: Base URL of proxy (default `http://localhost:8080`)
- `MATCH_DURATION`: Seconds each match lasts (default 30.0)
- `SPAWN_RATE`: Clients spawned per second; 0 = all at once (default 0)
- `GAME_SERVER_HOST_OVERRIDE`: Override game server host (for debugging against external server)

The load tester:
1. Spawns client threads (or gradually by spawn rate).
2. Each client:
   - Joins matchmaking (`POST /api/match/join`).
   - Polls status (`GET /api/match/status`) if not immediately matched.
   - Connects to game server via TCP when match is ready.
   - Waits for match end (or forces end after duration).
   - Sends end request (`POST /api/match/{session_id}/end`).

## Environment Variables

### Backend (set via Kubernetes manifests or `settings.py`)
- `HOSTNAME`: Pod name (auto-set by Kubernetes).
- `NAMESPACE`: Kubernetes namespace (from `settings.py`).
- `DATABASE_URL`: PostgreSQL connection string.
- `REDIS_HOST` / `REDIS_PORT`: Redis connection.
- `SESSION_SIZE`: Players per match (hard-coded in `settings.py`?).
- `MIN_PARTIAL_SESSION_SIZE`: Minimum players to start partial match.
- `FLUSH_WAIT_SECONDS`: Queue flush interval.

### Game Server (per-pod)
- `SESSION_ID`: Set by backend during pod creation.
- `PORT`: TCP port (default 8080).

### Load Tester
- See above.

## Project Structure

```
src/
├── app/
│   ├── backend/          # FastAPI matchmaking service
│   │   ├── main.py       # API endpoints, match logic
│   │   ├── storage.py    # DB/Redis connections, session tracking
│   │   └── k8s_game_server.py  # Kubernetes pod creation
│   ├── game-server/      # TCP game server (runs in pod)
│   │   └── main.py       # State machine, client handling
│   ├── load/             # Load testing tool
│   │   ├── client.py     # GameClient simulation
│   │   ├── lifecycle.py  # Single client lifecycle
│   │   └── main.py       # Entrypoint, argument parsing
│   └── proxy/            # (Not provided, but deployed via Makefile)
├── k8s/
│   └── base/             # Kubernetes manifests for backend & proxy
├── databases/            # K8s manifests for Redis & Postgres
└── scripts/              # Cluster setup/teardown (not provided)
```

## Development Notes

- Backend uses `kubernetes` client to create Deployments for game servers (one per match).
- Game server pods are labeled `app=game-server,session_id=<session_id>` for selection.
- Backend waits up to 45s for game server pod readiness before returning connection details.
- Match records are stored even if game server pod fails (use `ended_at` column for cleanup).
- Redis is optional; if unavailable, matchmaking degrades to local deque fallback (see `storage.py`).

## Teardown

```bash
# Delete all resources
make down
```

This runs `src/scripts/teardown.sh` to delete the kind cluster and associated resources.

## Limitations

- The provided code snippets are partial; some functions are truncated (e.g., `join_match` logic in `main.py`).
- `settings.py` is not included but is imported; must contain constants like `NAMESPACE`, `DATABASE_URL`, etc.
- Proxy implementation (`src/app/proxy/`) is not provided but referenced in Makefile.
- Database port-forwards assume local ports 6379 (Redis) and 5432 (Postgres); adjust if conflicts.

For production use, replace local settings with proper secrets management, increase timeouts, and implement authentication.
